# Alina Mirét Shah 
[amshah1022.github.io](https://amshah1022.github.io)

*Cornell University · B.A. Computer Science*  

Building reproducible evaluation and interpretability systems for transparent, reliable AI.

---

## Research Statement  
**[Triangulating AI Reliability: Evidence, Mechanisms, and Human Judgment](https://github.com/amshah1022/ai-reliability-agenda/blob/5c996fb8d73703d2632b70a5b8f6aa240339ef27/Triangulating_AI_Reliability___Statement_of_Direction__Alina_Shah_.pdf)**  
Outlines my direction toward a reliability layer for AI safety, integrating evidence-grounded evaluation, mechanistic interpretability, and human/rubric adjudication.  

---

## Current Projects  
- **Truth Layer** – Evidence-grounded evaluation framework that defines truthfulness as alignment with verifiable evidence.  
- **MedSimAI (Future of Learning Lab)** – Rubric-anchored dialogic feedback chatbot (Cornell–Yale–UCSF) for consistent medical-education feedback.  
- **ProbeEng (LAISR)** – Ensemble of 1k+ probes mapping reliability signals across layers and token positions.  

---

## Skills & Focus  
- Large Language Model Evaluation  
- Interpretability (TransformerLens, Probes)  
- Responsible / Reliable AI  
- Python · PyTorch · Pandas · NLP Pipelines  

---

## Affiliations  

Conducting multi-lab research on evaluation, interpretability, and human-aligned reliability systems.

**Cornell University**

Long-Term AI Safety Research Lab (Lionel Levine) — Interpretability reliability and meta-probing infrastructure; developing evaluation methods for model understanding tools.

Future of Learning Lab (René Kizilcec) — Rubric-anchored evaluation pipelines and dialogic feedback systems for reliable AI in education.

AI & Robotics Lab (Angelique Taylor) — Systematic review of multi-agent reinforcement learning applications in healthcare.

Culture & Computation Lab (David Mimno & Mathew Wilkens) — Representation alignment and literary corpus analysis using multimodal embeddings.

Former: Horizon Therapeutics · Stripe · Discovery Partners Institute (Alvin Chin)  

---

## Documents  
- [Resume (PDF)](https://github.com/amshah1022/amshah1022.github.io/blob/main/Alina_Miret_Shah_Resume.pdf)  

---

## Links  
- [GitHub](https://github.com/amshah1022)  
- [LinkedIn](https://linkedin.com/in/alinamshah)  
- [Email](mailto:alina.shah1022@gmail.com)  

---

## About Me  
I’m a researcher focused on developing auditable, evidence-based evaluation systems that make model reliability measurable. 
My goal is to bridge mechanistic interpretability, evidence-grounded NLP, and human-aligned evaluation to build transparent AI pipelines ready for oversight and safety-critical domains.  

---

_Last updated: October 2025_

_Site maintained by Alina M. Shah · amshah1022 @ gmail.com_
